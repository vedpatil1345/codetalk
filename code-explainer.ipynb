{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOzy8lH1x1RK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install streamlit langchain_groq pandas PyExecJs python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WidjC86qfb6"
   },
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import streamlit.components.v1 as components\n",
    "from typing import Dict, Any, Callable, Optional\n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import execjs\n",
    "from functools import lru_cache\n",
    "from dotenv import load_dotenv,set_key\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CodeLanguage(Enum):\n",
    "    PYTHON = \"python\"\n",
    "    JAVASCRIPT = \"javascript\"\n",
    "    JAVA = \"java\"\n",
    "    CPP = \"c++\"\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    content: str\n",
    "    is_bot: bool = False\n",
    "\n",
    "class CodeExecutor:\n",
    "    @staticmethod\n",
    "    def execute_python(code: str) -> str:\n",
    "        try:\n",
    "            # Use restricted globals for safety\n",
    "            restricted_globals = {\n",
    "                '__builtins__': {\n",
    "                    name: __builtins__[name]\n",
    "                    for name in ['print', 'len', 'str', 'int', 'float', 'list', 'dict']\n",
    "                }\n",
    "            }\n",
    "            exec(code, restricted_globals)\n",
    "            return \"Code executed successfully.\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Python execution error: {str(e)}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def execute_javascript(code: str) -> str:\n",
    "        try:\n",
    "            return str(execjs.eval(code))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"JavaScript execution error: {str(e)}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def execute_compiled_language(code: str, extension: str, compiler_cmd: list, cleanup_files: list) -> str:\n",
    "        temp_dir = Path(\"temp\")\n",
    "        temp_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        source_file = temp_dir / f\"Example{extension}\"\n",
    "        try:\n",
    "            # Write code to file\n",
    "            source_file.write_text(code)\n",
    "            \n",
    "            # Compile\n",
    "            compile_process = subprocess.run(\n",
    "                compiler_cmd, \n",
    "                capture_output=True, \n",
    "                text=True, \n",
    "                cwd=temp_dir\n",
    "            )\n",
    "            \n",
    "            if compile_process.returncode != 0:\n",
    "                return f\"Compilation error: {compile_process.stderr}\"\n",
    "            \n",
    "            # Run\n",
    "            run_cmd = [\"./Example\"] if extension == \".cpp\" else [\"java\", \"Example\"]\n",
    "            result = subprocess.run(\n",
    "                run_cmd,\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                timeout=5,\n",
    "                cwd=temp_dir\n",
    "            )\n",
    "            \n",
    "            return result.stdout\n",
    "            \n",
    "        except subprocess.TimeoutExpired:\n",
    "            return \"Error: Execution timed out\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Compilation/execution error: {str(e)}\")\n",
    "            return f\"Error: {str(e)}\"\n",
    "        finally:\n",
    "            # Cleanup\n",
    "            for file in cleanup_files:\n",
    "                try:\n",
    "                    (temp_dir / file).unlink(missing_ok=True)\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"Cleanup error for {file}: {str(e)}\")\n",
    "\n",
    "class CodeAnalyzer:\n",
    "    def __init__(self, api_key: Optional[str] = None):\n",
    "        # Try to get API key from environment variable if not provided\n",
    "        self.api_key = api_key or os.getenv('GROQ_API_KEY')\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"GROQ API key not found. Please set it in .env file or pass it directly.\")\n",
    "            \n",
    "        self.llm = ChatGroq(\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            groq_api_key=self.api_key,\n",
    "            temperature=0.9,\n",
    "            max_tokens=2048\n",
    "        )\n",
    "        \n",
    "    @lru_cache(maxsize=100)\n",
    "    def analyze_code(self, code: str, language: str) -> Dict[str, str]:\n",
    "        \"\"\"Analyze code with caching for improved performance\"\"\"\n",
    "        return {\n",
    "            'üë®üèª‚ÄçüíªCode-Explanation': self.explain_code(code, language),\n",
    "            'üìãRequirements Analysis': self.get_requirements(code),\n",
    "            '‚ö†Error Detection': self.get_error(code, language),\n",
    "            'üí™Code Improvement': self.get_improvements(code, language)\n",
    "        }\n",
    "    \n",
    "    def explain_code(self, code: str, language: str) -> str:\n",
    "        template = \"\"\"\n",
    "        As an AI code assistant, please provide a detailed explanation of this {language} code:\n",
    "        \n",
    "        {code}\n",
    "        \n",
    "        Focus on:\n",
    "        1. Overall purpose\n",
    "        2. Key components\n",
    "        3. Logic flow\n",
    "        4. Important functions/methods\n",
    "        \"\"\"\n",
    "        return self._get_llm_response(template, code=code, language=language)\n",
    "    \n",
    "    def get_requirements(self, code: str) -> str:\n",
    "        template = \"\"\"\n",
    "        List all requirements needed to run this code:\n",
    "        \n",
    "        {code}\n",
    "        \n",
    "        Include:\n",
    "        1. Dependencies\n",
    "        2. Environment setup\n",
    "        3. System requirements\n",
    "        4. Prerequisites\n",
    "        \"\"\"\n",
    "        return self._get_llm_response(template, code=code)\n",
    "    \n",
    "    def get_error(self, code: str, language: str) -> str:\n",
    "        template = \"\"\"\n",
    "        Analyze this {language} code for potential errors:\n",
    "        \n",
    "        {code}\n",
    "        \n",
    "        Consider:\n",
    "        1. Syntax errors\n",
    "        2. Logic errors\n",
    "        3. Common pitfalls\n",
    "        4. Edge cases\n",
    "        \"\"\"\n",
    "        return self._get_llm_response(template, code=code, language=language)\n",
    "    \n",
    "    def get_improvements(self, code: str, language: str) -> str:\n",
    "        template = \"\"\"\n",
    "        Suggest improvements for this {language} code:\n",
    "        \n",
    "        {code}\n",
    "        \n",
    "        Focus on:\n",
    "        1. Performance\n",
    "        2. Readability\n",
    "        3. Best practices\n",
    "        4. Security\n",
    "        \"\"\"\n",
    "        return self._get_llm_response(template, code=code, language=language)\n",
    "    \n",
    "    def _get_llm_response(self, template: str, **kwargs) -> str:\n",
    "        try:\n",
    "            prompt = PromptTemplate.from_template(template)\n",
    "            return self.llm.predict(prompt.format(**kwargs))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"LLM error: {str(e)}\")\n",
    "            return f\"Analysis failed: {str(e)}\"\n",
    "\n",
    "\n",
    "class CodeTalkApp:\n",
    "    def __init__(self):\n",
    "        self.initialize_session_state()\n",
    "        \n",
    "        # Handle API key input if not found in environment\n",
    "        api_key = os.getenv('GROQ_API_KEY')\n",
    "        if not api_key:\n",
    "            if 'api_key' not in st.session_state:\n",
    "                st.session_state.api_key = None\n",
    "                \n",
    "            if not st.session_state.api_key:\n",
    "                api_key = st.text_input(\"Enter your GROQ API key:\", type=\"password\")\n",
    "                if api_key:\n",
    "                    with open(\".env\", \"w\") as file:\n",
    "                        file.write(f\"GROQ_API_KEY = {api_key}\")\n",
    "                    st.session_state.api_key = api_key\n",
    "                    st.success(\"API key saved for this session!\")\n",
    "                    st.rerun()\n",
    "                return\n",
    "            \n",
    "            api_key = st.session_state.api_key\n",
    "            \n",
    "        try:\n",
    "            self.code_analyzer = CodeAnalyzer(api_key)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error initializing code analyzer: {str(e)}\")\n",
    "            return\n",
    "        \n",
    "    def initialize_session_state(self):\n",
    "        \"\"\"Initialize session state variables\"\"\"\n",
    "        defaults = {\n",
    "            'messages': [],\n",
    "            'code': \"\",\n",
    "            'error': \"\",\n",
    "            'analysis_results': None,  # New session state variable for analysis results\n",
    "            'theme': 'light',\n",
    "            'language': CodeLanguage.PYTHON.value,\n",
    "            'chat_history': [],\n",
    "            'current_code': \"\"  # New session state variable for current code\n",
    "        }\n",
    "        \n",
    "        for key, default_value in defaults.items():\n",
    "            if key not in st.session_state:\n",
    "                st.session_state[key] = default_value\n",
    "    \n",
    "    def render_code_analysis_tab(self):\n",
    "        code_col, chat_col = st.columns([1, 1])\n",
    "        \n",
    "        with code_col:\n",
    "            st.header(\"Code Analysis\")\n",
    "            selected_language = st.selectbox(\n",
    "                \"Select Code Language\",\n",
    "                [lang.value for lang in CodeLanguage],\n",
    "                key=\"language_selector\"\n",
    "            )\n",
    "            \n",
    "            code_input = st.text_area(\"Enter your code here:\", height=200, key=\"code_input\")\n",
    "            \n",
    "            if st.button(\"Analyze Code\") and code_input:\n",
    "                # Store the current code and analysis results in session state\n",
    "                st.session_state.current_code = code_input\n",
    "                st.session_state.analysis_results = self.code_analyzer.analyze_code(code_input, selected_language)\n",
    "            \n",
    "            # Display analysis results if they exist\n",
    "            if st.session_state.analysis_results:\n",
    "                for title, content in st.session_state.analysis_results.items():\n",
    "                    with st.expander(title):\n",
    "                        st.write(content)\n",
    "        \n",
    "        with chat_col:\n",
    "            self.render_chat_interface()\n",
    "    \n",
    "    def render_error_tab(self):\n",
    "        # Split into two columns\n",
    "        error_col, chat_col = st.columns([1, 1])\n",
    "        \n",
    "        with error_col:\n",
    "            st.header(\"Error Explainer\")\n",
    "            error_input = st.text_area(\"Paste your error message here:\", height=100)\n",
    "            st.markdown(\"### original Code(Optional)\")\n",
    "            code_context = st.text_area(\"Optional: Paste relevant code for better context\", height=150)\n",
    "            \n",
    "            if st.button(\"Analyze Error\") and error_input:\n",
    "                # Store current error context\n",
    "                st.session_state.current_error = {\n",
    "                    'message': error_input,\n",
    "                    'code_context': code_context\n",
    "                }\n",
    "                \n",
    "                # Generate comprehensive error analysis\n",
    "                analysis = self.analyze_error_comprehensive(error_input, code_context)\n",
    "                \n",
    "                # Display analysis in expandable sections\n",
    "                with st.expander(\"üîç Error Explanation\", expanded=True):\n",
    "                    st.markdown(analysis['explanation'])\n",
    "                \n",
    "                with st.expander(\"üõ†Ô∏è Solution Steps\"):\n",
    "                    st.markdown(analysis['solution'])\n",
    "                    \n",
    "                with st.expander(\"üö´ Common Pitfalls\"):\n",
    "                    st.markdown(analysis['pitfalls'])\n",
    "                    \n",
    "                with st.expander(\"üìö Related Resources\"):\n",
    "                    st.markdown(analysis['resources'])\n",
    "        \n",
    "        with chat_col:\n",
    "            st.header(\"Chat about the Error\")\n",
    "            # Display error-specific chat history\n",
    "            if 'error_chat_history' not in st.session_state:\n",
    "                st.session_state.error_chat_history = []\n",
    "                \n",
    "            for message in st.session_state.error_chat_history:\n",
    "                with st.chat_message(\"assistant\" if message.is_bot else \"user\"):\n",
    "                    st.markdown(message.content)\n",
    "            \n",
    "            # Chat input\n",
    "            user_message = st.chat_input(\"Ask about the error...\")\n",
    "            if user_message:\n",
    "                # Add user message to history\n",
    "                st.session_state.error_chat_history.append(Message(user_message, is_bot=False))\n",
    "                \n",
    "                # Generate context-aware response\n",
    "                error_context = f\"\"\"\n",
    "                Error message: {st.session_state.get('current_error', {}).get('message', '')}\n",
    "                Code context: {st.session_state.get('current_error', {}).get('code_context', '')}\n",
    "                Chat history: {[m.content for m in st.session_state.error_chat_history[-5:] if not m.is_bot]}\n",
    "                Current question: {user_message}\n",
    "                \"\"\"\n",
    "                \n",
    "                response = self.code_analyzer._get_llm_response(\n",
    "                    \"Given this error context:\\n{context}\\n\\nProvide a helpful, specific response addressing the user's question.\",\n",
    "                    context=error_context\n",
    "                )\n",
    "                \n",
    "                # Add bot response to history\n",
    "                st.session_state.error_chat_history.append(Message(response, is_bot=True))\n",
    "                st.rerun()\n",
    "\n",
    "    def analyze_error_comprehensive(self, error_message: str, code_context: str = \"\") -> Dict[str, str]:\n",
    "        \"\"\"Provide comprehensive error analysis with multiple aspects\"\"\"\n",
    "        \n",
    "        # Create context-aware prompt\n",
    "        base_context = f\"\"\"Error message: {error_message}\"\"\"\n",
    "        if code_context:\n",
    "            base_context += f\"\\nRelated code:\\n{code_context}\"\n",
    "        \n",
    "        # Generate explanation\n",
    "        explanation_prompt = f\"\"\"\n",
    "        {base_context}\n",
    "        \n",
    "        Provide a clear, detailed explanation of this error in markdown format, including:\n",
    "        1. What the error means in simple terms\n",
    "        2. The specific part of the code causing the error (if code is provided)\n",
    "        3. The underlying programming concept related to this error\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate solution steps\n",
    "        solution_prompt = f\"\"\"\n",
    "        {base_context}\n",
    "        \n",
    "        Provide step-by-step solutions in markdown format:\n",
    "        1. Immediate fix steps\n",
    "        2. Alternative approaches\n",
    "        3. How to verify the fix worked\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate common pitfalls\n",
    "        pitfalls_prompt = f\"\"\"\n",
    "        {base_context}\n",
    "        \n",
    "        List in markdown format:\n",
    "        1. Common mistakes that lead to this error\n",
    "        2. Similar errors to watch out for\n",
    "        3. Prevention tips\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate related resources\n",
    "        resources_prompt = f\"\"\"\n",
    "        {base_context}\n",
    "        \n",
    "        Provide in markdown format:\n",
    "        1. Related documentation links\n",
    "        2. Recommended learning resources\n",
    "        3. Similar error patterns to study\n",
    "        \"\"\"\n",
    "        \n",
    "        return {\n",
    "            'explanation': self.code_analyzer._get_llm_response(explanation_prompt),\n",
    "            'solution': self.code_analyzer._get_llm_response(solution_prompt),\n",
    "            'pitfalls': self.code_analyzer._get_llm_response(pitfalls_prompt),\n",
    "            'resources': self.code_analyzer._get_llm_response(resources_prompt)\n",
    "        }\n",
    "    \n",
    "    def render_chat_interface(self):\n",
    "        st.header(\"Chat About The Code\")\n",
    "        \n",
    "        # Display chat history\n",
    "        for message in st.session_state.chat_history:\n",
    "            with st.chat_message(\"assistant\" if message.is_bot else \"user\"):\n",
    "                st.markdown(message.content)\n",
    "        \n",
    "        # Chat input\n",
    "        user_message = st.chat_input(\"Ask a question about your code:\")\n",
    "        if user_message:\n",
    "            # Include current code context in the chat\n",
    "            context = f\"Given this code:\\n\\n{st.session_state.current_code}\\n\\nUser question: {user_message}\"\n",
    "            self.handle_chat_message(context)\n",
    "            st.rerun()\n",
    "    \n",
    "    def handle_chat_message(self, message: str):\n",
    "        # Store only the user's question in chat history, not the code context\n",
    "        user_question = message.split(\"User question: \")[-1]\n",
    "        st.session_state.chat_history.append(Message(user_question, is_bot=False))\n",
    "        \n",
    "        response = self.code_analyzer._get_llm_response(\n",
    "            \"{message}\\nResponse:\",\n",
    "            message=message\n",
    "        )\n",
    "        st.session_state.chat_history.append(Message(response, is_bot=True))\n",
    "        \n",
    "        # Add custom styling\n",
    "    def run(self):\n",
    "        st.set_page_config(page_title=\"CodeTalk\", layout=\"wide\")\n",
    "    \n",
    "        # Add custom styling with animation\n",
    "        st.markdown(\"\"\"\n",
    "        \n",
    "<style>\n",
    "        /* Reset default styles */\n",
    "* {\n",
    "    margin: 0;\n",
    "    padding: 0;\n",
    "    box-sizing: border-box;\n",
    "}\n",
    "\n",
    "html, body {\n",
    "    margin: 0;\n",
    "    padding: 0;\n",
    "    min-height: 100vh;\n",
    "    overflow-x: hidden;\n",
    "    position: relative;\n",
    "}\n",
    "\n",
    "/* Hide Streamlit header */\n",
    "header {\n",
    "    visibility: hidden;\n",
    "}\n",
    "\n",
    "/* Background layers container */\n",
    ".background-container {\n",
    "    position: fixed;  /* Changed to fixed to cover full viewport */\n",
    "    top: 0;\n",
    "    left: 0;\n",
    "    width: 100vw;\n",
    "    height: 100vh;\n",
    "    z-index: -1;\n",
    "}\n",
    ".top-bar {\n",
    "            position: fixed;\n",
    "            top: 0;\n",
    "            left: 0;\n",
    "            right: 0;\n",
    "            height: 60px;\n",
    "            background: linear-gradient(to bottom,\n",
    "                rgba(64, 64, 64, 0.8) 0%,\n",
    "                rgba(64, 64, 64, 0.5) 50%,\n",
    "                rgba(64, 64, 64, 0) 100%);\n",
    "            backdrop-filter: blur(4px);\n",
    "            -webkit-backdrop-filter: blur(4px);\n",
    "            z-index: 1000;\n",
    "        }\n",
    "/* Background animation layer */\n",
    ".animation {\n",
    "    position: absolute;\n",
    "    top: 0;\n",
    "    left: 0;\n",
    "    width: 100%;\n",
    "    height: 100%;\n",
    "    display: flex;\n",
    "    justify-content: space-between;\n",
    "    align-items: center;\n",
    "    z-index: 0;\n",
    "}\n",
    "\n",
    "/* Background gradient overlay */\n",
    ".app-bg {\n",
    "    position: absolute;\n",
    "    top: 60px;\n",
    "    left: 30px;\n",
    "    right:30px;\n",
    "    height: 100%;\n",
    "    background: linear-gradient(\n",
    "        145deg,\n",
    "        rgba(64, 64, 64, 0.60) 0%,\n",
    "        rgba(64, 64, 64, 0.65) 40%,\n",
    "        rgba(64, 64, 64, 0.70) 100%\n",
    "    );\n",
    "    align-self: center;\n",
    "    justify-content: center;\n",
    "    border: 1px solid rgba(255, 255, 255, 0.1);\n",
    "    border-radius: 25px;\n",
    "    backdrop-filter: blur(2px);\n",
    "    z-index: 1;\n",
    "}\n",
    "\n",
    "        \n",
    "        /* Main app container */\n",
    "        .stApp {\n",
    "            top: -50px;\n",
    "            background-color: rgba(0, 0, 0, 0.4);\n",
    "            z-index: 2;\n",
    "            left: 30px;\n",
    "            right: 30px;\n",
    "        }\n",
    "        \n",
    "        /* Custom container styling */\n",
    "        .css-1d391kg, .css-1n76uvr {\n",
    "            background-color: rgba(0, 0, 0, 0.45);\n",
    "            border-radius: 10px;\n",
    "            padding: 20px;\n",
    "            backdrop-filter: blur(10px);\n",
    "        }\n",
    "        \n",
    "        /* Input fields styling */\n",
    "        .stTextInput input, .stTextArea textarea {\n",
    "            background-color: rgba(255, 255, 255, 0.05);\n",
    "            color: white;\n",
    "            border: 1px solid rgba(255, 255, 255, 0.1);\n",
    "        }\n",
    "        \n",
    "        /* Button styling */\n",
    "        .stButton button {\n",
    "            background-color: #4a4a4a;\n",
    "            color: white;\n",
    "            border: none;\n",
    "        }\n",
    "        \n",
    "        /* Text color for all markdown and headings */\n",
    "        .stMarkdown, p, h1, h2, h3 {\n",
    "            color: white !important;\n",
    "        }   \n",
    "    </style>\n",
    "        \"\"\", unsafe_allow_html=True)\n",
    "\n",
    "            \n",
    "        st.markdown(\"\"\"<div class=\"top-bar\"></div><div class=\"background-container\"><iframe class=\"animation\" src=\"https://melodic-kataifi-1ba173.netlify.app\"></iframe><div class=\"app-bg\"></div></div>\"\"\",unsafe_allow_html=True)\n",
    "        \n",
    "        st.markdown(\"# CodeTalk\")\n",
    "    \n",
    "    # Rest of your code...\n",
    "        \n",
    "        if not hasattr(self, 'code_analyzer'):\n",
    "            return\n",
    "        \n",
    "        tab1, tab2 = st.tabs([\"üíª Code Analysis\", \"‚ö†Ô∏è Error Explainer\"])\n",
    "        \n",
    "        with tab1:\n",
    "            self.render_code_analysis_tab()\n",
    "        with tab2:\n",
    "            self.render_error_tab()\n",
    "        st.markdown(\"\"\"</div>\"\"\",unsafe_allow_html=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = CodeTalkApp()\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for on device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! streamlit run app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O - ipv4.icanhazip.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! streamlit run /content/app.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
